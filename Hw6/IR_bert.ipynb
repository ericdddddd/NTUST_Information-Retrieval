{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR-bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6b85b4af0364742b619cd478b97d93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_46effc6bad28431ea622610ab31bf860",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f00234ad857d4e8ca0c499b7b77ea531",
              "IPY_MODEL_9f0934f8ed1949038a10c47c5e1647b9"
            ]
          }
        },
        "46effc6bad28431ea622610ab31bf860": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f00234ad857d4e8ca0c499b7b77ea531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ab4b6208fe4e4d28a064931ad3d3280c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23cff50e8a80450c86679e0d331891bd"
          }
        },
        "9f0934f8ed1949038a10c47c5e1647b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_386565ef74ab412db19ebfef8e78ce46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.81MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd5cc4333f88452484651e3cdd744b5d"
          }
        },
        "ab4b6208fe4e4d28a064931ad3d3280c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23cff50e8a80450c86679e0d331891bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "386565ef74ab412db19ebfef8e78ce46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd5cc4333f88452484651e3cdd744b5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzgP_j7h97JV",
        "outputId": "8692f6fc-bbb9-4ca6-9f6e-00578255bf0a"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 24.0MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 31.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 21.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 24.9MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 23.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 26.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 17.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 18.8MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 17.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 17.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 17.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 17.5MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 17.5MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 17.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 17.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 17.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 17.5MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 17.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194kB 17.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 17.5MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 17.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 358kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 368kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 389kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 399kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 512kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 532kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 542kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 552kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 573kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 583kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 593kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 604kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 675kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 686kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 696kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 716kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 727kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 737kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 747kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 768kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 778kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 788kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 798kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 860kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 870kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 880kB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 890kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 911kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 921kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 931kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 942kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 952kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 962kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 972kB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 983kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2MB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.3MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 17.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5MB 17.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 17.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 17.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 54.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=c4f476bcdabb9a5abc340f88ea48eb476060e603949f65905c5248dfb87f410c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6OdHWky-jj5"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import time\r\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "c6b85b4af0364742b619cd478b97d93b",
            "46effc6bad28431ea622610ab31bf860",
            "f00234ad857d4e8ca0c499b7b77ea531",
            "9f0934f8ed1949038a10c47c5e1647b9",
            "ab4b6208fe4e4d28a064931ad3d3280c",
            "23cff50e8a80450c86679e0d331891bd",
            "386565ef74ab412db19ebfef8e78ce46",
            "cd5cc4333f88452484651e3cdd744b5d"
          ]
        },
        "id": "VZzI17z2-o67",
        "outputId": "6e3e2f00-ca17-48c7-b581-cb466268afcf"
      },
      "source": [
        "from transformers import BertTokenizer\r\n",
        "\r\n",
        "model_version = 'bert-base-uncased'\r\n",
        "tokenizer = BertTokenizer.from_pretrained(model_version)\r\n",
        "encoded_input = tokenizer(\"How old are you?\", \"I'm 6 years old\")\r\n",
        "print(encoded_input[\"input_ids\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6b85b4af0364742b619cd478b97d93b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[101, 2129, 2214, 2024, 2017, 1029, 102, 1045, 1005, 1049, 1020, 2086, 2214, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3hWw7YxA6eR"
      },
      "source": [
        "from torch.utils.data import Dataset\r\n",
        " \r\n",
        "class BertDataset(Dataset):\r\n",
        "    # 讀取前處理後的 tsv 檔並初始化一些參數\r\n",
        "    def __init__(self, mode, tokenizer):\r\n",
        "        assert mode in [\"train\", \"test\", \"val\"]  # 一般訓練你會需要 dev set\r\n",
        "        self.mode = mode\r\n",
        "        # 大數據你會需要用 iterator=True\r\n",
        "        if mode == 'train' :\r\n",
        "            self.positive_df = pd.read_csv(\"/content/drive/MyDrive/IR/IR/data/Hw6/all_postive.csv\").fillna(\"\")\r\n",
        "            self.negative_df = pd.read_csv(\"/content/drive/MyDrive/IR/IR/data/Hw6/BM25Top1000_negative.csv\").fillna(\"\")\r\n",
        "            self.len = len(self.positive_df)\r\n",
        "            self.data = 4\r\n",
        "        elif mode == 'val':\r\n",
        "            self.val_df = pd.read_csv(\"/content/drive/MyDrive/IR/IR/data/Hw6/validation_df.csv\").fillna(\"\")\r\n",
        "            self.len = len(self.val_df)\r\n",
        "            self.data = 1\r\n",
        "        else:\r\n",
        "            self.test_df = pd.read_csv(\"/content/drive/MyDrive/IR/IR/data/Hw6/test_df.csv\").fillna(\"\")\r\n",
        "            self.len = len(self.test_df)\r\n",
        "            self.data = 1\r\n",
        "        self.tokenizer = tokenizer  # 我們將使用 BERT tokenizer\r\n",
        "    \r\n",
        "    # 定義回傳一筆訓練 / 測試數據的函式\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        if self.mode == \"test\":\r\n",
        "            text_query = self.test_df.iloc[idx, 1]\r\n",
        "            text_doc = self.test_df.iloc[idx, 3]\r\n",
        "            label_tensor = None\r\n",
        "        elif self.mode == \"val\":\r\n",
        "            text_query = self.val_df.iloc[idx, 1]\r\n",
        "            text_doc = self.val_df.iloc[idx, 3]\r\n",
        "            label_tensor = None\r\n",
        "        else:\r\n",
        "            if idx > self.len:\r\n",
        "              idx = 0\r\n",
        "            positive_query = self.positive_df.iloc[idx, 0]\r\n",
        "            positive_docs = self.positive_df.iloc[idx, 2]\r\n",
        "            #隨機從negative中挑三篇出來\r\n",
        "            random_docs = np.random.randint(self.negative_df.shape[0], size=3)\r\n",
        "            negative_query = self.negative_df.iloc[random_docs,0].values\r\n",
        "            negative_docs = self.negative_df.iloc[random_docs,2].values\r\n",
        "            \r\n",
        "            # 將 label 文字也轉換成索引方便轉換成 tensor\r\n",
        "            positive_doc_insert = idx % 4\r\n",
        "            label_tensor = torch.tensor(positive_doc_insert).unsqueeze(0)\r\n",
        "            label_tensor = label_tensor.type(torch.LongTensor)\r\n",
        "            \r\n",
        "            positive_doc = [positive_query,positive_docs]\r\n",
        "            negative_doc1 = [negative_query[0],negative_docs[0]]\r\n",
        "            negative_doc2 = [negative_query[1],negative_docs[1]]\r\n",
        "            negative_doc3 = [negative_query[2],negative_docs[2]]\r\n",
        "            bert_input = [negative_doc1,negative_doc2,negative_doc3]\r\n",
        "            bert_input.insert(positive_doc_insert,positive_doc)\r\n",
        "        \r\n",
        "        # test , training 時所需要的資料量不一樣大\r\n",
        "        input_ids = torch.zeros([self.data, 512], dtype=torch.long)\r\n",
        "        token_type_ids = torch.zeros([self.data, 512], dtype=torch.long)\r\n",
        "        attention_mask = torch.zeros([self.data, 512], dtype=torch.long)\r\n",
        "        \r\n",
        "        if self.mode == 'train':\r\n",
        "            encoded_input = tokenizer(bert_input , truncation ='longest_first',return_tensors=\"pt\" ,padding = True)\r\n",
        "        else:\r\n",
        "            encoded_input = tokenizer(text_query,text_doc, truncation ='longest_first',return_tensors='pt', padding=True)\r\n",
        "        \r\n",
        "        bert_input_shape = list(encoded_input['input_ids'].size())\r\n",
        "        word_size = bert_input_shape[1]\r\n",
        "        \r\n",
        "        input_ids[:,:word_size] = encoded_input['input_ids']\r\n",
        "        token_type_ids[:,:word_size] = encoded_input['token_type_ids']\r\n",
        "        attention_mask[:,:word_size] = encoded_input['attention_mask']\r\n",
        "        \r\n",
        "        #return (encoded_input['input_ids'] ,encoded_input['token_type_ids'] ,encoded_input['attention_mask'], label_tensor)\r\n",
        "        if self.mode == 'train':\r\n",
        "          return (input_ids,token_type_ids,attention_mask,label_tensor)\r\n",
        "          #return (input_ids,attention_mask,label_tensor)\r\n",
        "        return(input_ids,token_type_ids,attention_mask)\r\n",
        "        #return(input_ids,attention_mask)\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return self.len\r\n",
        "    \r\n",
        "    \r\n",
        "# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\r\n",
        "train_data = BertDataset(\"train\", tokenizer=tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkVbQN7hDKfI",
        "outputId": "b177908a-fee2-4667-e1d2-62182a2fcf45"
      },
      "source": [
        "print(len(train_data))\r\n",
        "data = train_data[0]\r\n",
        "print(data[0])\r\n",
        "print(data[3])\r\n",
        "#data1 = train_data[1]\r\n",
        "print(tokenizer.convert_ids_to_tokens(data[0][0]))\r\n",
        "#print(tokenizer.convert_ids_to_tokens(data[0][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8614\n",
            "tensor([[  101, 14955, 18994,  ...,  8186,  8315,   102],\n",
            "        [  101,  4675, 21156,  ...,  2005,  1996,   102],\n",
            "        [  101,  2304,  4562,  ...,  1050,  1032,   102],\n",
            "        [  101,  2248,  2396,  ...,  2088,  1032,   102]])\n",
            "tensor([0])\n",
            "['[CLS]', 'pol', '##iom', '##ye', '##lit', '##is', 'and', 'post', '-', 'pol', '##io', '[SEP]', '[', \"'\", 'language', ':', '<', 'f', 'p', '=', '105', '>', 'chinese', '<', '/', 'f', '>', '\\\\', 'n', 'article', 'type', ':', 'cs', '##o', '\\\\', 'n', '\\\\', 'n', '<', 'f', 'p', '=', '106', '>', '[', 'article', 'by', 'zhao', 'zhu', '##lian', '##g', '(', '63', '##9', '##2', '45', '##54', '53', '##28', ')', 'of', 'the', 'central', '<', '/', 'f', '>', '\\\\', 'n', 'china', 'teachers', '\\\\', \"'\", 'college', ',', 'edited', 'by', 'xu', 'hong', '##hai', '(', '60', '##7', '##9', '134', '##7', '318', '##9', ')', ':', '\\\\', 'n', '\"', 'the', 'state', 'of', 'china', '\\\\', \"'\", 's', 'physically', 'challenged', 'persons', 'in', 'the', '\\\\', 'n', 'course', 'of', 'modernization', '\"', ']', '\\\\', 'n', '[', 'excerpt', ']', '[', 'passage', 'omitted', ']', '\\\\', 'n', 'in', 'recent', 'years', ',', 'along', 'with', 'the', 'development', 'of', 'china', '\\\\', \"'\", 's', '\\\\', 'n', 'physically', 'challenged', 'persons', '\\\\', \"'\", 'cause', ',', 'while', 'the', 'condition', 'of', '\\\\', 'n', 'this', 'large', 'and', 'special', 'group', 'has', 'improved', 'to', 'a', 'certain', 'extent', ',', '\\\\', 'n', 'the', 'current', 'state', 'of', 'physically', 'challenged', 'in', 'areas', 'such', 'as', '\\\\', 'n', 'economics', ',', 'education', ',', 'jobs', ',', 'and', 'recovery', ',', 'generally', 'remains', 'far', '\\\\', 'n', 'behind', 'the', 'average', 'level', 'of', 'the', 'society', 'as', 'a', 'whole', '.', '\\\\', 'n', '1', '.', 'the', 'threat', '-', 'to', '-', 'survival', 'crisis', '.', 'statistics', 'show', '\\\\', 'n', 'that', 'of', 'the', '4', '.', '9', 'percent', 'of', 'china', '\\\\', \"'\", 's', 'population', 'that', 'are', '\\\\', 'n', 'physically', 'challenged', ',', 'as', 'many', 'as', '20', 'million', 'are', 'struggling', 'to', '\\\\', 'n', 'survive', 'below', 'the', 'subsistence', 'line', ',', 'with', '70', 'percent', 'of', '\\\\', 'n', 'physically', 'challenged', 'existing', 'only', 'with', 'the', 'support', 'of', 'family', '\\\\', 'n', 'and', 'relatives', 'or', 'on', 'state', 'or', 'collective', 'relief', '.', '\\\\', 'n', 'a', 'study', 'reported', 'in', 'the', '1993', 'no', '2', 'issue', 'of', 'z', '##hong', '##gu', '##o', 'can', '##ji', '\\\\', 'n', 'ren', '\\\\', 'n', '[', 'china', '\\\\', \"'\", 's', 'disabled', 'persons', ']', 'says', 'that', ':', '\"', 'many', 'physically', '\\\\', 'n', 'challenged', 'remain', 'in', 'great', 'hardship', ',', 'with', 'basically', 'not', 'enough', '\\\\', 'n', 'food', 'and', 'clothing', '.', 'for', 'instance', ',', 'in', 'sha', '##oya', '##ng', 'city', ',', 'hunan', '\\\\', 'n', 'province', ',', 'where', 'economic', 'conditions', 'are', 'better', ',', 'the', 'average', '\\\\', 'n', 'income', 'in', '1991', 'was', '54', '##5', '.', '19', 'yuan', 'for', 'the', 'rural', 'population', ',', 'but', '\\\\', 'n', 'only', '264', '.', '64', 'yuan', 'for', 'physically', 'challenged', ',', 'or', 'less', 'than', '\\\\', 'n', 'one', '-', 'half', '.', 'in', 'sha', '##oya', '##ng', '\\\\', \"'\", 's', 'xi', '##nni', '##ng', 'county', ',', 'poverty', '-', 'stricken', '\\\\', 'n', 'physically', 'challenged', 'make', 'up', '64', '.', '4', 'percent', 'of', 'all', 'physically', '\\\\', 'n', 'challenged', ',', 'with', '17', '.', '2', 'percent', 'in', 'exceptional', 'poverty', '.', '\"', '\\\\', 'n', 'a', 'document', 'put', 'out', 'by', 'the', 'china', 'coalition', 'for', 'the', 'disabled', '\\\\', 'n', '(', 'the', '1992', 'document', 'no', '126', 'of', 'the', 'coalition', 'for', 'the', 'disabled', ')', '\\\\', 'n', 'contains', 'the', 'following', 'item', ':', 'while', 'poverty', 'relief', 'is', 'carried', '\\\\', 'n', 'out', ',', 'in', 'certain', 'developed', 'or', 'more', 'developed', 'areas', ',', '70', '-', '80', 'percent', '\\\\', 'n', 'of', 'the', 'poverty', '-', 'strike', '##n', 'population', 'below', 'the', 'local', 'subsistence', '\\\\', 'n', 'line', 'are', 'physically', 'challenged', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3gIQ1ygDRA9",
        "outputId": "2fc1a177-d929-464c-c96b-d34cbf6311fe"
      },
      "source": [
        "testset =  BertDataset(\"test\", tokenizer=tokenizer)\r\n",
        "validation_set = BertDataset(\"val\", tokenizer=tokenizer)\r\n",
        "print(len(testset))\r\n",
        "print(len(validation_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80000\n",
            "20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTQanQ0L50AJ",
        "outputId": "3ca82172-2eb8-41c9-823f-56edfce1a099"
      },
      "source": [
        "print(testset[0][0].size())\r\n",
        "print(validation_set[0][0].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512])\n",
            "torch.Size([1, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukz--vR0DVaz"
      },
      "source": [
        "from torch.utils.data import DataLoader\r\n",
        "TRAIN_BATCH_SIZE = 3\r\n",
        "TEST_BATCH_SIZE = 10\r\n",
        "testloader = DataLoader(testset, batch_size = TEST_BATCH_SIZE,drop_last=True,num_workers=2)\r\n",
        "validationloader = DataLoader(validation_set, batch_size = TEST_BATCH_SIZE,drop_last=True,num_workers=2)\r\n",
        "trainloader = DataLoader(train_data, batch_size = TRAIN_BATCH_SIZE,drop_last=True,num_workers=2,shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzUl868fV5lC",
        "outputId": "5355e234-fafa-4e40-bf71-39a799b37c9f"
      },
      "source": [
        "print(len(testloader))\r\n",
        "print(len(trainloader))\r\n",
        "print(len(validationloader))\r\n",
        "#print(len(validationloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000\n",
            "2871\n",
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WsLs02QEGqM",
        "outputId": "263bbf49-94fe-4b93-ce66-3839887938f3"
      },
      "source": [
        "data = next(iter(trainloader))\r\n",
        "\r\n",
        "tokens_tensors = data[0]\r\n",
        "segments_tensors = data[1]\r\n",
        "masks_tensors = data[2]\r\n",
        "label_ids = data[3]\r\n",
        "print(f\"\"\"\r\n",
        "tokens_tensors.shape   = {tokens_tensors.shape} \r\n",
        "{tokens_tensors}\r\n",
        "------------------------\r\n",
        "segments_tensors.shape = {segments_tensors.shape}\r\n",
        "{segments_tensors}\r\n",
        "------------------------\r\n",
        "masks_tensors.shape    = {masks_tensors.shape}\r\n",
        "{masks_tensors}\r\n",
        "------------------------\r\n",
        "label_ids.shape        = {label_ids.shape}\r\n",
        "{label_ids}\r\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tokens_tensors.shape   = torch.Size([3, 4, 512]) \n",
            "tensor([[[  101,  4238,  1011,  ...,     0,     0,     0],\n",
            "         [  101,  3919,  5949,  ...,  1010,  2143,   102],\n",
            "         [  101,  8673,  4288,  ...,  8347,  1998,   102],\n",
            "         [  101, 24787,  6897,  ...,  2025,  2018,   102]],\n",
            "\n",
            "        [[  101,  5850,  1010,  ...,  2011,  1032,   102],\n",
            "         [  101,  4675, 21156,  ...,  2637,  1005,   102],\n",
            "         [  101,  7115, 10186,  ...,  5876,  2000,   102],\n",
            "         [  101, 11268, 16281,  ...,     0,     0,     0]],\n",
            "\n",
            "        [[  101,  7227, 14338,  ...,     0,     0,     0],\n",
            "         [  101, 24787,  6897,  ...,  4650,  1010,   102],\n",
            "         [  101, 13730,  2075,  ..., 18250,  2566,   102],\n",
            "         [  101, 18479, 26029,  ...,  1032,  1050,   102]]])\n",
            "------------------------\n",
            "segments_tensors.shape = torch.Size([3, 4, 512])\n",
            "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 1, 1, 1],\n",
            "         [0, 0, 0,  ..., 1, 1, 1],\n",
            "         [0, 0, 0,  ..., 1, 1, 1]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 1, 1, 1],\n",
            "         [0, 0, 0,  ..., 1, 1, 1],\n",
            "         [0, 0, 0,  ..., 1, 1, 1],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 1, 1, 1],\n",
            "         [0, 0, 0,  ..., 1, 1, 1],\n",
            "         [0, 0, 0,  ..., 1, 1, 1]]])\n",
            "------------------------\n",
            "masks_tensors.shape    = torch.Size([3, 4, 512])\n",
            "tensor([[[1, 1, 1,  ..., 0, 0, 0],\n",
            "         [1, 1, 1,  ..., 1, 1, 1],\n",
            "         [1, 1, 1,  ..., 1, 1, 1],\n",
            "         [1, 1, 1,  ..., 1, 1, 1]],\n",
            "\n",
            "        [[1, 1, 1,  ..., 1, 1, 1],\n",
            "         [1, 1, 1,  ..., 1, 1, 1],\n",
            "         [1, 1, 1,  ..., 1, 1, 1],\n",
            "         [1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0],\n",
            "         [1, 1, 1,  ..., 1, 1, 1],\n",
            "         [1, 1, 1,  ..., 1, 1, 1],\n",
            "         [1, 1, 1,  ..., 1, 1, 1]]])\n",
            "------------------------\n",
            "label_ids.shape        = torch.Size([3, 1])\n",
            "tensor([[2],\n",
            "        [0],\n",
            "        [2]])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pItN_EGK5h6C",
        "outputId": "62ea8770-4f76-4d14-b7c9-2969fc54fa3e"
      },
      "source": [
        "data = next(iter(testloader))\r\n",
        "print(data[0].size())\r\n",
        "print(data[1].size())\r\n",
        "print(data[2].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 1, 512])\n",
            "torch.Size([10, 1, 512])\n",
            "torch.Size([10, 1, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuGTx6VoEPnq",
        "outputId": "0d54fc95-2d13-4f06-92a3-5dbd276ce9e5"
      },
      "source": [
        "from transformers import BertForMultipleChoice\r\n",
        "\r\n",
        "PRETRAINED_MODEL_NAME = \"/content/drive/MyDrive/IR/IR/data/Hw6/bert_v2\"\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(\"device:\", device)\r\n",
        "print(torch.cuda.get_device_name(0))\r\n",
        "\r\n",
        "model = BertForMultipleChoice.from_pretrained(\r\n",
        "    PRETRAINED_MODEL_NAME)\r\n",
        "\r\n",
        "model = model.to(device)\r\n",
        "# high-level 顯示此模型裡的 modules\r\n",
        "print(\"\"\"\r\n",
        "name            module\r\n",
        "----------------------\"\"\")\r\n",
        "for name, module in model.named_children():\r\n",
        "    if name == \"bert\":\r\n",
        "        for n, _ in module.named_children():\r\n",
        "            print(f\"{name}:{n}\")\r\n",
        "    else:\r\n",
        "        print(\"{:15} {}\".format(name, module))\r\n",
        "print(model.config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda:0\n",
            "Tesla T4\n",
            "\n",
            "name            module\n",
            "----------------------\n",
            "bert:embeddings\n",
            "bert:encoder\n",
            "bert:pooler\n",
            "dropout         Dropout(p=0.1, inplace=False)\n",
            "classifier      Linear(in_features=768, out_features=1, bias=True)\n",
            "BertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/IR/IR/data/Hw6/bert_v2\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMultipleChoice\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byDxDGvEEeeW",
        "outputId": "92763411-6559-4ada-c264-4fa89facc684"
      },
      "source": [
        "# 訓練模式\r\n",
        "model.train(mode = True)\r\n",
        "\r\n",
        "# 使用 Adam Optim 更新整個分類模型的參數\r\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\r\n",
        "TRAIN_BATCH_SIZE = 3\r\n",
        "EPOCHS = 2\r\n",
        "start = time.time()\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "    s1 = time.time()\r\n",
        "    running_loss = 0.0\r\n",
        "    for batch_num ,data in enumerate(trainloader):\r\n",
        "\r\n",
        "        if batch_num % 100 == 0:\r\n",
        "          print('now batch_num : ' + str(batch_num))\r\n",
        "        \"\"\"\r\n",
        "        tokens_tensors, segments_tensors, \\\r\n",
        "        masks_tensors, labels = [t.to(device) for t in data]\r\n",
        "        \"\"\"\r\n",
        "        tokens_tensors = data[0].to(device)\r\n",
        "        segments_tensors = data[1].to(device)\r\n",
        "        masks_tensors = data[2].to(device)\r\n",
        "        labels = data[3].view(TRAIN_BATCH_SIZE).to(device)\r\n",
        "        \r\n",
        "        # 將參數梯度歸零\r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        # forward pass\r\n",
        "        outputs = model(input_ids=tokens_tensors, \r\n",
        "                        token_type_ids=segments_tensors, \r\n",
        "                        attention_mask=masks_tensors, \r\n",
        "                        labels=labels)\r\n",
        "\r\n",
        "        loss = outputs.loss\r\n",
        "        # backward\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        # 紀錄當前 batch loss\r\n",
        "        running_loss += loss.item()\r\n",
        "        \r\n",
        "    print('[epoch %d] loss: %.3f' %\r\n",
        "          (epoch + 1, running_loss))\r\n",
        "    s2 = time.time()\r\n",
        "    print('this epoch costs :' +  str((s2 - s1) / 60) + 'mins')\r\n",
        "    \r\n",
        "end = time.time()\r\n",
        "print('total time :' +  str((end - start) / 60) + 'mins')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "now batch_num : 0\n",
            "now batch_num : 100\n",
            "now batch_num : 200\n",
            "now batch_num : 300\n",
            "now batch_num : 400\n",
            "now batch_num : 500\n",
            "now batch_num : 600\n",
            "now batch_num : 700\n",
            "now batch_num : 800\n",
            "now batch_num : 900\n",
            "now batch_num : 1000\n",
            "now batch_num : 1100\n",
            "now batch_num : 1200\n",
            "now batch_num : 1300\n",
            "now batch_num : 1400\n",
            "now batch_num : 1500\n",
            "now batch_num : 1600\n",
            "now batch_num : 1700\n",
            "now batch_num : 1800\n",
            "now batch_num : 1900\n",
            "now batch_num : 2000\n",
            "now batch_num : 2100\n",
            "now batch_num : 2200\n",
            "now batch_num : 2300\n",
            "now batch_num : 2400\n",
            "now batch_num : 2500\n",
            "now batch_num : 2600\n",
            "now batch_num : 2700\n",
            "now batch_num : 2800\n",
            "[epoch 1] loss: 1216.338\n",
            "this epoch costs :85.94273754755656mins\n",
            "now batch_num : 0\n",
            "now batch_num : 100\n",
            "now batch_num : 200\n",
            "now batch_num : 300\n",
            "now batch_num : 400\n",
            "now batch_num : 500\n",
            "now batch_num : 600\n",
            "now batch_num : 700\n",
            "now batch_num : 800\n",
            "now batch_num : 900\n",
            "now batch_num : 1000\n",
            "now batch_num : 1100\n",
            "now batch_num : 1200\n",
            "now batch_num : 1300\n",
            "now batch_num : 1400\n",
            "now batch_num : 1500\n",
            "now batch_num : 1600\n",
            "now batch_num : 1700\n",
            "now batch_num : 1800\n",
            "now batch_num : 1900\n",
            "now batch_num : 2000\n",
            "now batch_num : 2100\n",
            "now batch_num : 2200\n",
            "now batch_num : 2300\n",
            "now batch_num : 2400\n",
            "now batch_num : 2500\n",
            "now batch_num : 2600\n",
            "now batch_num : 2700\n",
            "now batch_num : 2800\n",
            "[epoch 2] loss: 606.102\n",
            "this epoch costs :85.89665374755859mins\n",
            "total time :171.83939873377483mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKEbqE_G3yaB"
      },
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/IR/IR/data/Hw6/bert_v2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OuSxn-93EZ3"
      },
      "source": [
        "model.eval()\r\n",
        "def get_predictions(model, dataloader):\r\n",
        "    \r\n",
        "    score = None\r\n",
        "    with torch.no_grad():\r\n",
        "        # 遍巡整個資料集\r\n",
        "        for batch_num ,data in enumerate(dataloader):\r\n",
        "            # 將所有 tensors 移到 GPU 上\r\n",
        "            if batch_num % 200 == 0:\r\n",
        "                print('now batch :' + str(batch_num))\r\n",
        "            \"\"\"\r\n",
        "            if next(model.parameters()).is_cuda:\r\n",
        "                data = [t.to(\"cuda:0\") for t in data if t is not None]\r\n",
        "            \"\"\"\r\n",
        "            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\r\n",
        "            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\r\n",
        "            tokens_tensors = data[0].to(device)\r\n",
        "            segments_tensors = data[1].to(device)\r\n",
        "            masks_tensors = data[2].to(device)\r\n",
        "            outputs = model(input_ids=tokens_tensors, \r\n",
        "                            token_type_ids=segments_tensors, \r\n",
        "                            attention_mask=masks_tensors)\r\n",
        "            \r\n",
        "            logits = outputs.logits\r\n",
        "            logits = logits.detach().cpu().numpy()\r\n",
        "            if score is None:\r\n",
        "                score = logits\r\n",
        "            else:\r\n",
        "                score = np.concatenate((score, logits), axis=None)\r\n",
        "            \r\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUSulg5QJdhO"
      },
      "source": [
        "# 讓模型跑在 GPU 上並取得訓練集的分類準確率\r\n",
        "bert_score = get_predictions(model, validationloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HclQOk3Wv3ot",
        "outputId": "efecc697-6cdc-4c8c-88a7-40ebe7e929c7"
      },
      "source": [
        "pip install ml_metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ml_metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/c1/e7/c31a2dd37045a0c904bee31c2dbed903d4f125a6ce980b91bae0c961abb8/ml_metrics-0.1.4.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ml_metrics) (1.19.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ml_metrics) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->ml_metrics) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->ml_metrics) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->ml_metrics) (1.15.0)\n",
            "Building wheels for collected packages: ml-metrics\n",
            "  Building wheel for ml-metrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-metrics: filename=ml_metrics-0.1.4-cp36-none-any.whl size=7849 sha256=16b7fa198fea554fa577a8fa2f1d108ee8bcec5fe7edeb77877aa3eb571d0c77\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/61/2d/776be7b8a4f14c5db48c8e5451451cabc58dc6aa7ee3801163\n",
            "Successfully built ml-metrics\n",
            "Installing collected packages: ml-metrics\n",
            "Successfully installed ml-metrics-0.1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RSLIyM3lJMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82da8b35-c250-4051-bdcc-33da94f33eff"
      },
      "source": [
        "import ml_metrics\r\n",
        "\r\n",
        "bert_score = np.load('/content/drive/MyDrive/IR/IR/data/Hw6/scores/validation_score.npy')\r\n",
        "queries = pd.read_csv(\"/content/drive/MyDrive/IR/IR/data/Hw6/train_20queries.csv\").fillna(\"\")\r\n",
        "val_data = pd.read_csv(\"/content/drive/MyDrive/IR/IR/data/Hw6/validation_df.csv\").fillna(\"\")\r\n",
        "topk = 1000\r\n",
        "positive_docs = queries['pos_doc_ids']\r\n",
        "\r\n",
        "alpha_arr = np.arange(0,5,0.1)\r\n",
        "result = np.zeros(alpha_arr.shape)\r\n",
        "\r\n",
        "for index,alpha in enumerate(alpha_arr):\r\n",
        "  print(alpha)\r\n",
        "  sum = 0\r\n",
        "  for query_num in range(20):\r\n",
        "    res = {}\r\n",
        "    BM25_docs = val_data['relevant_docs'][topk * query_num : topk * (query_num + 1)].tolist()\r\n",
        "    BM25_score = val_data['BM25_score'][topk * query_num : topk * (query_num + 1)].to_numpy()\r\n",
        "    query_positive = positive_docs[query_num].split()\r\n",
        "    new_score = BM25_score + alpha * bert_score[topk * query_num : topk * (query_num + 1)]\r\n",
        "\r\n",
        "    for i,j in zip(BM25_docs,new_score):\r\n",
        "        res[i] = j\r\n",
        "    sorted_x = sorted(res.items(), key=lambda kv: kv[1],reverse = True)\r\n",
        "    rescore_docs = []\r\n",
        "    for doc in sorted_x:\r\n",
        "        rescore_docs.append(doc[0])\r\n",
        "    \r\n",
        "    score = ml_metrics.mapk(query_positive,rescore_docs,topk)\r\n",
        "    sum += score\r\n",
        "  #sum /= 20\r\n",
        "  result[index] = sum\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.1\n",
            "0.2\n",
            "0.30000000000000004\n",
            "0.4\n",
            "0.5\n",
            "0.6000000000000001\n",
            "0.7000000000000001\n",
            "0.8\n",
            "0.9\n",
            "1.0\n",
            "1.1\n",
            "1.2000000000000002\n",
            "1.3\n",
            "1.4000000000000001\n",
            "1.5\n",
            "1.6\n",
            "1.7000000000000002\n",
            "1.8\n",
            "1.9000000000000001\n",
            "2.0\n",
            "2.1\n",
            "2.2\n",
            "2.3000000000000003\n",
            "2.4000000000000004\n",
            "2.5\n",
            "2.6\n",
            "2.7\n",
            "2.8000000000000003\n",
            "2.9000000000000004\n",
            "3.0\n",
            "3.1\n",
            "3.2\n",
            "3.3000000000000003\n",
            "3.4000000000000004\n",
            "3.5\n",
            "3.6\n",
            "3.7\n",
            "3.8000000000000003\n",
            "3.9000000000000004\n",
            "4.0\n",
            "4.1000000000000005\n",
            "4.2\n",
            "4.3\n",
            "4.4\n",
            "4.5\n",
            "4.6000000000000005\n",
            "4.7\n",
            "4.800000000000001\n",
            "4.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbsRxj2Q2lRV",
        "outputId": "51f4d55e-1cc3-436f-f5cd-07c6b1b49e65"
      },
      "source": [
        "print(bert_score)\r\n",
        "print(result)\r\n",
        "print(alpha_arr[np.argmax(result)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2.5805001  0.5930148  1.1736164 ... -5.1854014 -2.352374  -5.742383 ]\n",
            "[7.67803851 7.75981385 7.98230821 8.06469741 8.12944284 8.19857088\n",
            " 8.16263364 8.11960409 8.10048649 8.18003132 8.16349967 8.16869207\n",
            " 8.1237614  8.0392753  8.02806107 8.03430165 8.05758752 8.07203656\n",
            " 8.05198078 7.92557411 7.92862077 7.99631964 7.98442845 7.98124033\n",
            " 7.89143218 7.87725817 7.86601341 7.9044918  7.87159487 7.88008801\n",
            " 7.89600454 7.82795096 7.83369022 7.8584135  7.88339822 7.91257075\n",
            " 7.96558947 7.96731611 7.97364259 8.00030598 8.02946647 8.02929493\n",
            " 8.05310422 8.04861403 8.08621117 8.05900091 8.04186507 8.06102167\n",
            " 8.04261651 8.01422513]\n",
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q0eULyCI3RI",
        "outputId": "be15485f-a133-4572-e49c-7c63fae55df1"
      },
      "source": [
        "print(len(testloader))\r\n",
        "score = get_predictions(model, testloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000\n",
            "now batch :0\n",
            "now batch :200\n",
            "now batch :400\n",
            "now batch :600\n",
            "now batch :800\n",
            "now batch :1000\n",
            "now batch :1200\n",
            "now batch :1400\n",
            "now batch :1600\n",
            "now batch :1800\n",
            "now batch :2000\n",
            "now batch :2200\n",
            "now batch :2400\n",
            "now batch :2600\n",
            "now batch :2800\n",
            "now batch :3000\n",
            "now batch :3200\n",
            "now batch :3400\n",
            "now batch :3600\n",
            "now batch :3800\n",
            "now batch :4000\n",
            "now batch :4200\n",
            "now batch :4400\n",
            "now batch :4600\n",
            "now batch :4800\n",
            "now batch :5000\n",
            "now batch :5200\n",
            "now batch :5400\n",
            "now batch :5600\n",
            "now batch :5800\n",
            "now batch :6000\n",
            "now batch :6200\n",
            "now batch :6400\n",
            "now batch :6600\n",
            "now batch :6800\n",
            "now batch :7000\n",
            "now batch :7200\n",
            "now batch :7400\n",
            "now batch :7600\n",
            "now batch :7800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_uHF3-ulVzC"
      },
      "source": [
        "np.save('/content/drive/MyDrive/IR/IR/data/Hw6/scores/validation_score.npy',bert_score)\r\n",
        "np.save('/content/drive/MyDrive/IR/IR/data/Hw6/scores/result_score.npy',score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAu4fG6_3z8Y",
        "outputId": "7349be15-ea1c-42f4-e30e-f85b9f2de5a7"
      },
      "source": [
        "result_score = np.load('/content/drive/MyDrive/IR/IR/data/Hw6/scores/result_score.npy')\r\n",
        "print(result_score.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEAUUwnF78cS"
      },
      "source": [
        "test_data = pd.read_csv(\"/content/drive/MyDrive/IR/IR/data/Hw6/test_df.csv\").fillna(0)\r\n",
        "topk = 1000\r\n",
        "alpha = 2.8\r\n",
        "result_csv = pd.DataFrame(columns = [\"query_id\" , \"ranked_doc_ids\"])\r\n",
        "for query_num in range(80):\r\n",
        "    res = {}\r\n",
        "    relevant_docs = test_data['relevant_docs'][topk * query_num : topk * (query_num + 1)].tolist()\r\n",
        "    query_id = test_data['query_num'][query_num * topk].astype('int32')\r\n",
        "    query_BM25_score = test_data['BM25_score'][topk * query_num : topk * (query_num + 1)].to_numpy()\r\n",
        "    new_score = query_BM25_score + alpha * result_score[topk * query_num : topk * (query_num + 1)]\r\n",
        "    for i,j in zip(relevant_docs,new_score):\r\n",
        "        res[i] = j\r\n",
        "    sorted_x = sorted(res.items(), key=lambda kv: kv[1],reverse = True)\r\n",
        "    text = \"\"\r\n",
        "    for doc in sorted_x:\r\n",
        "        text += doc[0] + \" \"\r\n",
        "    d = {\"query_id\": query_id ,\"ranked_doc_ids\": text}\r\n",
        "    this_query_df = pd.DataFrame(data = d ,index=[0])\r\n",
        "    result_csv = pd.concat([result_csv , this_query_df] , ignore_index = True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpS1i461Rprl",
        "outputId": "75ebf822-d8f6-4084-d85c-203d8dbf326e"
      },
      "source": [
        "print(result_csv.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy77ucUFB26m"
      },
      "source": [
        "result_csv.to_csv(\"/content/drive/MyDrive/IR/IR/data/Hw6/result/result_alpha2.88_v2.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}